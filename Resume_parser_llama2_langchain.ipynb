{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "16672339",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T12:18:53.585265Z",
          "iopub.status.busy": "2023-08-19T12:18:53.584954Z",
          "iopub.status.idle": "2023-08-19T12:26:43.829205Z",
          "shell.execute_reply": "2023-08-19T12:26:43.827904Z",
          "shell.execute_reply.started": "2023-08-19T12:18:53.585225Z"
        },
        "papermill": {
          "duration": 0.008268,
          "end_time": "2023-08-19T13:04:24.586888",
          "exception": false,
          "start_time": "2023-08-19T13:04:24.578620",
          "status": "completed"
        },
        "tags": [],
        "id": "16672339"
      },
      "source": [
        "## **In This Notebook, I have built a Resume Parser Application using Llama2 model and langchain framework**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "242e4069",
      "metadata": {
        "papermill": {
          "duration": 0.007693,
          "end_time": "2023-08-19T13:04:24.602163",
          "exception": false,
          "start_time": "2023-08-19T13:04:24.594470",
          "status": "completed"
        },
        "tags": [],
        "id": "242e4069"
      },
      "source": [
        "### Apart from Langchain, we also need to Install Auto GPTQ as we would be using Quantized version of Llama2 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9737c279",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:04:24.619612Z",
          "iopub.status.busy": "2023-08-19T13:04:24.618808Z",
          "iopub.status.idle": "2023-08-19T13:11:32.460180Z",
          "shell.execute_reply": "2023-08-19T13:11:32.458825Z"
        },
        "papermill": {
          "duration": 427.853313,
          "end_time": "2023-08-19T13:11:32.462896",
          "exception": false,
          "start_time": "2023-08-19T13:04:24.609583",
          "status": "completed"
        },
        "tags": [],
        "id": "9737c279",
        "outputId": "b30fbe6a-e209-428b-c394-bd82028e8bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
            "google-cloud-pubsublite 1.8.2 requires overrides<7.0.0,>=6.0.1, but you have overrides 7.4.0 which is incompatible.\r\n",
            "jupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq torch==2.0.1 --progress-bar off\n",
        "!pip install -qqq transformers==4.31.0 --progress-bar off\n",
        "!pip install -qqq langchain==0.0.266 --progress-bar off\n",
        "!pip install -qqq openai==0.27.4 --progress-bar off\n",
        "!pip install -Uqqq watermark==2.3.1 --progress-bar off\n",
        "!pip install -Uqqq chromadb==0.4.5 --progress-bar off\n",
        "!pip install -Uqqq tiktoken==0.3.3 --progress-bar off\n",
        "!pip install -Uqqq youtube-transcript-api==0.5.0 --progress-bar off\n",
        "!pip install -Uqqq pytube==12.1.3 --progress-bar off\n",
        "!pip install -qqq sentence_transformers==2.2.2 --progress-bar off\n",
        "!pip install -qqq InstructorEmbedding==1.0.1  --progress-bar off\n",
        "!pip install -qqq xformers==0.0.20  --progress-bar off\n",
        "!pip install -Uqqq unstructured[local-inference]==0.5.12 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82f15a3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:11:32.481549Z",
          "iopub.status.busy": "2023-08-19T13:11:32.481212Z",
          "iopub.status.idle": "2023-08-19T13:11:33.805429Z",
          "shell.execute_reply": "2023-08-19T13:11:33.804062Z"
        },
        "papermill": {
          "duration": 1.336888,
          "end_time": "2023-08-19T13:11:33.808444",
          "exception": false,
          "start_time": "2023-08-19T13:11:32.471556",
          "status": "completed"
        },
        "tags": [],
        "id": "a82f15a3"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/PanQiWei/AutoGPTQ/releases/download/v0.4.1/auto_gptq-0.4.1+cu118-cp310-cp310-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1029d39",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:11:33.826550Z",
          "iopub.status.busy": "2023-08-19T13:11:33.825564Z",
          "iopub.status.idle": "2023-08-19T13:11:47.671217Z",
          "shell.execute_reply": "2023-08-19T13:11:47.669848Z"
        },
        "papermill": {
          "duration": 13.857465,
          "end_time": "2023-08-19T13:11:47.673879",
          "exception": false,
          "start_time": "2023-08-19T13:11:33.816414",
          "status": "completed"
        },
        "tags": [],
        "id": "c1029d39"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq auto_gptq-0.4.1+cu118-cp310-cp310-linux_x86_64.whl --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96db426",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:11:47.692338Z",
          "iopub.status.busy": "2023-08-19T13:11:47.691428Z",
          "iopub.status.idle": "2023-08-19T13:12:05.207250Z",
          "shell.execute_reply": "2023-08-19T13:12:05.206213Z"
        },
        "papermill": {
          "duration": 17.527644,
          "end_time": "2023-08-19T13:12:05.209681",
          "exception": false,
          "start_time": "2023-08-19T13:11:47.682037",
          "status": "completed"
        },
        "tags": [],
        "id": "d96db426",
        "outputId": "8ee7e63f-91a2-44f6-fe19-c20b0cdc9ef1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import textwrap\n",
        "import torch\n",
        "import chromadb\n",
        "import langchain\n",
        "import openai\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import TextLoader, UnstructuredPDFLoader, YoutubeLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.llms import OpenAI, HuggingFacePipeline\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.prompts import PromptTemplate\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "from transformers import AutoTokenizer, pipeline, logging, TextStreamer\n",
        "from langchain.document_loaders.image import UnstructuredImageLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be30874a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:12:05.227373Z",
          "iopub.status.busy": "2023-08-19T13:12:05.227038Z",
          "iopub.status.idle": "2023-08-19T13:12:05.233219Z",
          "shell.execute_reply": "2023-08-19T13:12:05.232300Z"
        },
        "papermill": {
          "duration": 0.017546,
          "end_time": "2023-08-19T13:12:05.235376",
          "exception": false,
          "start_time": "2023-08-19T13:12:05.217830",
          "status": "completed"
        },
        "tags": [],
        "id": "be30874a"
      },
      "outputs": [],
      "source": [
        "def print_response(response: str):\n",
        "    print(\"\\n\".join(textwrap.wrap(response, width=100)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fefe65af",
      "metadata": {
        "papermill": {
          "duration": 0.008232,
          "end_time": "2023-08-19T13:12:05.251485",
          "exception": false,
          "start_time": "2023-08-19T13:12:05.243253",
          "status": "completed"
        },
        "tags": [],
        "id": "fefe65af"
      },
      "source": [
        "### Load Resume, Split into chunks of 2K characters, convert to embeddings using Instruct Embeddings and store in chroma DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02d20206",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:12:05.269878Z",
          "iopub.status.busy": "2023-08-19T13:12:05.268200Z",
          "iopub.status.idle": "2023-08-19T13:12:05.275293Z",
          "shell.execute_reply": "2023-08-19T13:12:05.274399Z"
        },
        "papermill": {
          "duration": 0.018141,
          "end_time": "2023-08-19T13:12:05.277439",
          "exception": false,
          "start_time": "2023-08-19T13:12:05.259298",
          "status": "completed"
        },
        "tags": [],
        "id": "02d20206"
      },
      "outputs": [],
      "source": [
        "pdf_loader = UnstructuredPDFLoader(\"/content/input/CV1_.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skRRCYuaLXTd"
      },
      "id": "skRRCYuaLXTd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZSqgu5gWLXn3"
      },
      "id": "ZSqgu5gWLXn3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e055c99e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:12:05.295801Z",
          "iopub.status.busy": "2023-08-19T13:12:05.294332Z",
          "iopub.status.idle": "2023-08-19T13:12:07.402462Z",
          "shell.execute_reply": "2023-08-19T13:12:07.401400Z"
        },
        "papermill": {
          "duration": 2.120323,
          "end_time": "2023-08-19T13:12:07.405680",
          "exception": false,
          "start_time": "2023-08-19T13:12:05.285357",
          "status": "completed"
        },
        "tags": [],
        "id": "e055c99e"
      },
      "outputs": [],
      "source": [
        "pdf_pages = pdf_loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9f75386",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:12:07.437374Z",
          "iopub.status.busy": "2023-08-19T13:12:07.436896Z",
          "iopub.status.idle": "2023-08-19T13:12:07.453247Z",
          "shell.execute_reply": "2023-08-19T13:12:07.452318Z"
        },
        "papermill": {
          "duration": 0.033677,
          "end_time": "2023-08-19T13:12:07.456153",
          "exception": false,
          "start_time": "2023-08-19T13:12:07.422476",
          "status": "completed"
        },
        "tags": [],
        "id": "b9f75386",
        "outputId": "f3365232-2368-4aef-b823-5b115251a62c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(pdf_pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff8bbf9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:12:07.480166Z",
          "iopub.status.busy": "2023-08-19T13:12:07.479772Z",
          "iopub.status.idle": "2023-08-19T13:12:07.490165Z",
          "shell.execute_reply": "2023-08-19T13:12:07.489247Z"
        },
        "papermill": {
          "duration": 0.0251,
          "end_time": "2023-08-19T13:12:07.492724",
          "exception": false,
          "start_time": "2023-08-19T13:12:07.467624",
          "status": "completed"
        },
        "tags": [],
        "id": "7ff8bbf9",
        "outputId": "5e8ce565-642a-4b25-f8e0-3f899545955e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=512)\n",
        "texts = text_splitter.split_documents(pdf_pages)\n",
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "225b571e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:12:07.515665Z",
          "iopub.status.busy": "2023-08-19T13:12:07.515347Z",
          "iopub.status.idle": "2023-08-19T13:12:22.538810Z",
          "shell.execute_reply": "2023-08-19T13:12:22.537759Z"
        },
        "papermill": {
          "duration": 15.039927,
          "end_time": "2023-08-19T13:12:22.543550",
          "exception": false,
          "start_time": "2023-08-19T13:12:07.503623",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "75773ebc3ba345dd82e91450778ae23c",
            "30108498b7424b8c8b572e1f454ddfbe",
            "7ba39e2a348944c496d854d2bfdeb35a",
            "c041d58f50484b2a97c1e267fc03fb6e",
            "cba6eb73db1c45a6a389c77780b9eea8",
            "7888cc315a8d4bbd960a8bf75aabb3c1",
            "9f5882e7872845c0b97e032176e48a9a",
            "7bfa4b39d01243af8de408d1332a7e03",
            "d98edf68c65e4c35a762cb134b3e13a7",
            "afbe890c43a74397857151de48b9a8a4",
            "be28c0f37a2340648c0fc588357da62d",
            "22d018778e0f4c42a43213b08a109776",
            "e6ca3b83753440d3b23ec32054daa803",
            "9902a455ea73454d9a025fe78a641c60"
          ]
        },
        "id": "225b571e",
        "outputId": "8a810fec-fa00-4037-cad5-c8c01a740e93"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75773ebc3ba345dd82e91450778ae23c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)c7233/.gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30108498b7424b8c8b572e1f454ddfbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ba39e2a348944c496d854d2bfdeb35a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/2_Dense/config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c041d58f50484b2a97c1e267fc03fb6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/3.15M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cba6eb73db1c45a6a389c77780b9eea8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)9fb15c7233/README.md:   0%|          | 0.00/66.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7888cc315a8d4bbd960a8bf75aabb3c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)b15c7233/config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f5882e7872845c0b97e032176e48a9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bfa4b39d01243af8de408d1332a7e03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d98edf68c65e4c35a762cb134b3e13a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afbe890c43a74397857151de48b9a8a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be28c0f37a2340648c0fc588357da62d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22d018778e0f4c42a43213b08a109776",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)c7233/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6ca3b83753440d3b23ec32054daa803",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.41k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9902a455ea73454d9a025fe78a641c60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)15c7233/modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ],
      "source": [
        "model_name = \"hkunlp/instructor-large\"\n",
        "\n",
        "hf_embeddings = HuggingFaceInstructEmbeddings(\n",
        "    model_name = model_name) ## , model_kwargs = {'device': 'cuda'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4168b6b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:12:22.571628Z",
          "iopub.status.busy": "2023-08-19T13:12:22.571241Z",
          "iopub.status.idle": "2023-08-19T13:12:30.344161Z",
          "shell.execute_reply": "2023-08-19T13:12:30.342943Z"
        },
        "papermill": {
          "duration": 7.789435,
          "end_time": "2023-08-19T13:12:30.346627",
          "exception": false,
          "start_time": "2023-08-19T13:12:22.557192",
          "status": "completed"
        },
        "tags": [],
        "id": "d4168b6b"
      },
      "outputs": [],
      "source": [
        "db = Chroma.from_documents(texts, hf_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed3b8039",
      "metadata": {
        "papermill": {
          "duration": 0.011357,
          "end_time": "2023-08-19T13:12:30.369081",
          "exception": false,
          "start_time": "2023-08-19T13:12:30.357724",
          "status": "completed"
        },
        "tags": [],
        "id": "ed3b8039"
      },
      "source": [
        "### Initialize the Quantized Llama2 Model from Huggingface, and warp it by Langchain's HuggingFace Pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17cad9c4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:12:30.392800Z",
          "iopub.status.busy": "2023-08-19T13:12:30.392443Z",
          "iopub.status.idle": "2023-08-19T13:14:02.222148Z",
          "shell.execute_reply": "2023-08-19T13:14:02.221113Z"
        },
        "papermill": {
          "duration": 91.8444,
          "end_time": "2023-08-19T13:14:02.224794",
          "exception": false,
          "start_time": "2023-08-19T13:12:30.380394",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "8b8bd88746574c549224c9fa5e86aced",
            "0bedf31e7222472584a4c61a88b722f7",
            "bf9fa2d6b0cf4da5b787938ec37f4423",
            "56133fb1b3be41bd899e0aeecfc6dd20",
            "1df3d1038089446087b9146ce8b3ac1e",
            "b7be8c9581ef450d9d80f2168c0a81e3",
            "6285f39e04ef4580bb0c979217414965"
          ]
        },
        "id": "17cad9c4",
        "outputId": "c589cdb5-5ecf-45d9-9f1d-0d9f4659b20c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b8bd88746574c549224c9fa5e86aced",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bedf31e7222472584a4c61a88b722f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf9fa2d6b0cf4da5b787938ec37f4423",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56133fb1b3be41bd899e0aeecfc6dd20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1df3d1038089446087b9146ce8b3ac1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7be8c9581ef450d9d80f2168c0a81e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)quantize_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6285f39e04ef4580bb0c979217414965",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)bit-128g.safetensors:   0%|          | 0.00/7.26G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
        "model_basename = \"gptq_model-4bit-128g\"\n",
        "\n",
        "use_triton = False\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "\n",
        "model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\n",
        "        model_basename=model_basename,\n",
        "        use_safetensors=True,\n",
        "        trust_remote_code=True,\n",
        "        device='cuda:0',\n",
        "        use_triton=use_triton,\n",
        "        quantize_config=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f220f8c9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:14:02.250435Z",
          "iopub.status.busy": "2023-08-19T13:14:02.250121Z",
          "iopub.status.idle": "2023-08-19T13:14:02.866021Z",
          "shell.execute_reply": "2023-08-19T13:14:02.864828Z"
        },
        "papermill": {
          "duration": 0.631093,
          "end_time": "2023-08-19T13:14:02.868242",
          "exception": false,
          "start_time": "2023-08-19T13:14:02.237149",
          "status": "completed"
        },
        "tags": [],
        "id": "f220f8c9",
        "outputId": "d5d57481-0fc3-49c1-9a9b-23926be71145"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ],
      "source": [
        "streamer = TextStreamer(tokenizer, skip_prompt = True, skip_special_tokens = True)\n",
        "text_pipeline = pipeline(task = 'text-generation', model = model, tokenizer = tokenizer, streamer = streamer)\n",
        "llm = HuggingFacePipeline(pipeline = text_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d477d982",
      "metadata": {
        "papermill": {
          "duration": 0.011985,
          "end_time": "2023-08-19T13:14:02.892605",
          "exception": false,
          "start_time": "2023-08-19T13:14:02.880620",
          "status": "completed"
        },
        "tags": [],
        "id": "d477d982"
      },
      "source": [
        "### Prompt function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fced2173",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:14:02.918026Z",
          "iopub.status.busy": "2023-08-19T13:14:02.917676Z",
          "iopub.status.idle": "2023-08-19T13:14:02.922415Z",
          "shell.execute_reply": "2023-08-19T13:14:02.921416Z"
        },
        "papermill": {
          "duration": 0.020223,
          "end_time": "2023-08-19T13:14:02.924526",
          "exception": false,
          "start_time": "2023-08-19T13:14:02.904303",
          "status": "completed"
        },
        "tags": [],
        "id": "fced2173"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(prompt, sys_prompt):\n",
        "    return f\"[INST] <<SYS>> {sys_prompt} <</SYS>> {prompt} [/INST]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794b4e88",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:14:02.949344Z",
          "iopub.status.busy": "2023-08-19T13:14:02.949068Z",
          "iopub.status.idle": "2023-08-19T13:14:02.955390Z",
          "shell.execute_reply": "2023-08-19T13:14:02.954457Z"
        },
        "papermill": {
          "duration": 0.021235,
          "end_time": "2023-08-19T13:14:02.957442",
          "exception": false,
          "start_time": "2023-08-19T13:14:02.936207",
          "status": "completed"
        },
        "tags": [],
        "id": "794b4e88"
      },
      "outputs": [],
      "source": [
        "sys_prompt = \"Use following piece of context to answer the question in less than 20 words\"\n",
        "template = generate_prompt(\n",
        "    \"\"\"\n",
        "    {context}\n",
        "\n",
        "    Question : {question}\n",
        "    \"\"\"\n",
        "    , sys_prompt)\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6db1d37b",
      "metadata": {
        "papermill": {
          "duration": 0.011651,
          "end_time": "2023-08-19T13:14:02.981020",
          "exception": false,
          "start_time": "2023-08-19T13:14:02.969369",
          "status": "completed"
        },
        "tags": [],
        "id": "6db1d37b"
      },
      "source": [
        "### Initialize Langchain's Q&A Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3949fbe1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:14:03.006180Z",
          "iopub.status.busy": "2023-08-19T13:14:03.005896Z",
          "iopub.status.idle": "2023-08-19T13:14:03.012605Z",
          "shell.execute_reply": "2023-08-19T13:14:03.011727Z"
        },
        "papermill": {
          "duration": 0.021949,
          "end_time": "2023-08-19T13:14:03.014796",
          "exception": false,
          "start_time": "2023-08-19T13:14:02.992847",
          "status": "completed"
        },
        "tags": [],
        "id": "3949fbe1"
      },
      "outputs": [],
      "source": [
        "chain_type_kwargs = {\"prompt\": prompt}\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    return_source_documents = True,\n",
        "    chain_type_kwargs=chain_type_kwargs,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01d74def",
      "metadata": {
        "papermill": {
          "duration": 0.011798,
          "end_time": "2023-08-19T13:14:03.038211",
          "exception": false,
          "start_time": "2023-08-19T13:14:03.026413",
          "status": "completed"
        },
        "tags": [],
        "id": "01d74def"
      },
      "source": [
        "### Have a chat with Resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc536edf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:14:03.064525Z",
          "iopub.status.busy": "2023-08-19T13:14:03.063686Z",
          "iopub.status.idle": "2023-08-19T13:14:09.323205Z",
          "shell.execute_reply": "2023-08-19T13:14:09.322246Z"
        },
        "papermill": {
          "duration": 6.275632,
          "end_time": "2023-08-19T13:14:09.325530",
          "exception": false,
          "start_time": "2023-08-19T13:14:03.049898",
          "status": "completed"
        },
        "tags": [],
        "id": "dc536edf",
        "outputId": "efa74c88-e783-4c70-d27a-886e82d00a86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (4096) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Sure! Here's the answer to the question in less than 20 words:\n",
            "\n",
            "Candidate worked on uplift modeling, model uncertainty estimation, chat intent classification, and machine verse projects.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"what projects candidate worked on ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c10d5e5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:14:09.355889Z",
          "iopub.status.busy": "2023-08-19T13:14:09.355562Z",
          "iopub.status.idle": "2023-08-19T13:14:12.369723Z",
          "shell.execute_reply": "2023-08-19T13:14:12.368792Z"
        },
        "papermill": {
          "duration": 3.031891,
          "end_time": "2023-08-19T13:14:12.371985",
          "exception": false,
          "start_time": "2023-08-19T13:14:09.340094",
          "status": "completed"
        },
        "tags": [],
        "id": "5c10d5e5",
        "outputId": "21808441-9100-417c-98e7-13d3b35a0a71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Sure! Here's the answer to your question in less than 20 words:\n",
            "\n",
            "Candidate studied at IIT Kharagpur.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"where did candidate study?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd326bc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:14:12.405886Z",
          "iopub.status.busy": "2023-08-19T13:14:12.404991Z",
          "iopub.status.idle": "2023-08-19T13:14:25.215055Z",
          "shell.execute_reply": "2023-08-19T13:14:25.214083Z"
        },
        "papermill": {
          "duration": 12.828917,
          "end_time": "2023-08-19T13:14:25.217416",
          "exception": false,
          "start_time": "2023-08-19T13:14:12.388499",
          "status": "completed"
        },
        "tags": [],
        "id": "bbd326bc",
        "outputId": "4851f309-eac7-4cdd-a6db-9ec9d3f11de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the provided context, the candidate has the following skillset:\n",
            "\n",
            "* Experience in deriving insights and intelligence from Credit Bureau, Card transaction, and closed loop Data.\n",
            "* Strong knowledge of multiple ML domains like Time Series, Model Interpretability, NLP, Computer Vision.\n",
            "* Leadership experience as a Manager, leading a team of 3 Data Scientists.\n",
            "* Proficient in using various data science tools such as Transformer, Shapelet, CNN, LSTM, GNN, GBM, and SHAP, Lime, Integrated Gradient.\n",
            "* Familiarity with programming languages such as Python, Pandas, NumPy, and PySpark, Hive.\n",
            "* Strong understanding of Credit Risk, Credit Bureaus, Closed Loop Transaction, Spend Analytics, Loan Portfolio, and Credit Line.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"what skillset candidate has?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d03b16",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:14:25.268568Z",
          "iopub.status.busy": "2023-08-19T13:14:25.266820Z",
          "iopub.status.idle": "2023-08-19T13:14:28.020570Z",
          "shell.execute_reply": "2023-08-19T13:14:28.019549Z"
        },
        "papermill": {
          "duration": 2.781299,
          "end_time": "2023-08-19T13:14:28.022920",
          "exception": false,
          "start_time": "2023-08-19T13:14:25.241621",
          "status": "completed"
        },
        "tags": [],
        "id": "92d03b16",
        "outputId": "c69e28ed-96e1-4fdb-f4c9-eed072d9a09e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the given context, the contact details of the candidate are:\n",
            "\n",
            "dd1996@gmail.com\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"what's the contact detail of candidate?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c6acc9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:14:28.078280Z",
          "iopub.status.busy": "2023-08-19T13:14:28.077914Z",
          "iopub.status.idle": "2023-08-19T13:14:30.316487Z",
          "shell.execute_reply": "2023-08-19T13:14:30.315463Z"
        },
        "papermill": {
          "duration": 2.268812,
          "end_time": "2023-08-19T13:14:30.318904",
          "exception": false,
          "start_time": "2023-08-19T13:14:28.050092",
          "status": "completed"
        },
        "tags": [],
        "id": "25c6acc9",
        "outputId": "85573d5d-2f0b-4c4e-8d6a-872d4c483a2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the given context, the candidate has 4 years of work experience.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"how many years of work experience candidate has?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77b49f4d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T13:14:30.372719Z",
          "iopub.status.busy": "2023-08-19T13:14:30.372381Z",
          "iopub.status.idle": "2023-08-19T13:14:34.768915Z",
          "shell.execute_reply": "2023-08-19T13:14:34.767906Z"
        },
        "papermill": {
          "duration": 4.425976,
          "end_time": "2023-08-19T13:14:34.771171",
          "exception": false,
          "start_time": "2023-08-19T13:14:30.345195",
          "status": "completed"
        },
        "tags": [],
        "id": "77b49f4d",
        "outputId": "5750e268-b0de-48e1-8c2c-0248934ec8dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Sure! Here is the answer to your question in less than 20 words:\n",
            "\n",
            "Candidate worked at American Express in a leadership role as a Data Scientist, and also worked at other companies with job titles such as Data Scientist and Manager.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"In which companies with what jobtitle did candidate work?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b4a40b6",
      "metadata": {
        "papermill": {
          "duration": 0.028231,
          "end_time": "2023-08-19T13:14:34.828624",
          "exception": false,
          "start_time": "2023-08-19T13:14:34.800393",
          "status": "completed"
        },
        "tags": [],
        "id": "7b4a40b6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 624.028291,
      "end_time": "2023-08-19T13:14:38.479063",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-08-19T13:04:14.450772",
      "version": "2.4.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}